{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as tf\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "from torchvision import transforms\n",
    "\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(in_channels=2, out_channels=32, kernel_size=5, padding=2, weight_mean=0.8, weight_std=0.05)\n",
    "        self.conv1_t = 10\n",
    "        self.k1 = 5\n",
    "        self.r1 = 2\n",
    "\n",
    "        self.conv2 = snn.Convolution(32, 150, 2, 1, 0.8, 0.05)\n",
    "        self.conv2_t = 1\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.tconv1 = snn.TransposeConvolution(in_channels=32,out_channels=2,kernel_size=5,padding=2)\n",
    "        self.tconv2 = snn.TransposeConvolution(150,32,2,1)\n",
    "\n",
    "        self.stdp1 = snn.STDP(self.conv1, (0.004, -0.003))\n",
    "        self.stdp2 = snn.STDP(self.conv2, (0.004, -0.003))\n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "\n",
    "    def forward(self, input, max_layer):\n",
    "        spk_in = input.float()\n",
    "\n",
    "        if self.training:\n",
    "            # convolution 1\n",
    "            pot = self.conv1(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "\n",
    "            # apply stdp to convolution 1\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if self.spk_cnt1 >= 500:\n",
    "                    self.spk_cnt1 = 0\n",
    "                    ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            # max pool 1\n",
    "            spk_pooled, pool1_indices = tf.max_pool2d(spk, 2, 2,return_indices=True)\n",
    "\n",
    "            # print(f\"input conv1:\\t{spk_in.shape}\")\n",
    "            # print(f\"output conv1:\\t{spk.shape}\")\n",
    "\n",
    "            # print(f\"pool1:\\t\\t{spk_pooled.shape}\")\n",
    "\n",
    "            # convolution 2\n",
    "            spk_in = spk_pooled\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "\n",
    "            # apply stdp to convolution 2\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if self.spk_cnt2 >= 500:\n",
    "                    self.spk_cnt2 = 0\n",
    "                    ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            # print(f\"input conv2:\\t{spk_in.shape}\")\n",
    "            # print(f\"output conv2:\\t{spk.shape}\")\n",
    "\n",
    "            # load weights for transpose convolutions\n",
    "            self.tconv2.load_weight(torch.transpose(self.conv2.weight,2,3))\n",
    "            self.tconv1.load_weight(torch.transpose(self.conv1.weight,2,3))\n",
    "            \n",
    "            # transpose convolution 2\n",
    "            spk_in = spk\n",
    "            pot = self.tconv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "\n",
    "            # max unpool 1\n",
    "            spk_unpooled = tf.max_unpool2d(spk, pool1_indices, 2, 2)\n",
    "\n",
    "            # print(f\"input tconv2:\\t{spk_in.shape}\")\n",
    "            # print(f\"output conv2:\\t{spk.shape}\")\n",
    "            \n",
    "            # print(f\"unpool2:\\t{spk_unpooled.shape}\")\n",
    "\n",
    "            # transpose convolution 1\n",
    "            spk_in = spk_unpooled\n",
    "            pot = self.tconv1(spk_in)\n",
    "            spk = sf.fire(pot, self.conv1_t)\n",
    "\n",
    "            # print(f\"input tconv2:\\t{spk_in.shape}\")\n",
    "            # print(f\"output conv2:\\t{spk.shape}\")\n",
    "\n",
    "            return spk, pot\n",
    "        else:\n",
    "            # convolution 1\n",
    "            pot = self.conv1(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            # max pool 1\n",
    "            spk_pooled, pool1_indices = tf.max_pool2d(spk, 2, 2,return_indices=True)\n",
    "\n",
    "            # convolution 2\n",
    "            spk_in = spk_pooled\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            \n",
    "            # load weights for transpose convolutions\n",
    "            self.tconv2.load_weight(torch.transpose(self.conv2.weight,2,3))\n",
    "            self.tconv1.load_weight(torch.transpose(self.conv1.weight,2,3))\n",
    "            \n",
    "            # transpose convolution 2\n",
    "            spk_in = spk\n",
    "            pot = self.tconv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "\n",
    "            # max unpool 1\n",
    "            spk_unpooled = tf.max_unpool2d(spk, pool1_indices, 2, 2)\n",
    "\n",
    "            # transpose convolution 1\n",
    "            spk_in = spk_unpooled\n",
    "            pot = self.tconv1(spk_in)\n",
    "            spk = sf.fire(pot, self.conv1_t)\n",
    "\n",
    "            return spk\n",
    "    \n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torchvision\n",
    "\n",
    "\n",
    "# # Define some random input data\n",
    "# input_data = torch.randn(1, 2, 28, 28)  # Batch size of 1, 1 channel, 5x5 input\n",
    "# plt.imshow(input_data[0][0])\n",
    "# plt.show()\n",
    "# print(input_data.shape)\n",
    "\n",
    "# # Define a 2D convolution layer with padding\n",
    "# conv = snn.Convolution(in_channels=2, out_channels=32, kernel_size=5, padding=2, weight_mean=0.8, weight_std=0.05)\n",
    "\n",
    "# # Apply the convolution\n",
    "# conv_output = conv(input_data)\n",
    "# print(conv_output.shape)\n",
    "\n",
    "# # Define a transpose convolution layer with the same parameters\n",
    "# tconv = snn.TransposeConvolution(in_channels=32,out_channels=2,kernel_size=5,padding=2)\n",
    "# tconv.load_weight(torch.transpose(conv.weight, 2,3))\n",
    "# # print(conv.weight[0][0],'\\n',tconv.weight[0][0])\n",
    "\n",
    "# # Apply the transpose convolution\n",
    "# trans_conv_output = tconv(conv_output)\n",
    "# print(trans_conv_output.shape)\n",
    "# plt.imshow(trans_conv_output[0][0])\n",
    "# plt.show()\n",
    "\n",
    "# # Check if the output of the transpose convolution matches the input\n",
    "# print(torch.allclose(input_data, trans_conv_output, atol=1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def test(network, data, target, layer_idx):\n",
    "    network.eval()\n",
    "    ans = [None] * len(data)\n",
    "    t = [None] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        output,_ = network(data_in, layer_idx).max(dim = 0)\n",
    "        ans[i] = output.reshape(-1).cpu().numpy()\n",
    "        t[i] = target[i]\n",
    "    return np.array(ans), np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Spike Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1Transform:\n",
    "    def __init__(self, filter, timesteps = 15):\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 1000 == 0:\n",
    "            print(self.cnt)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()\n",
    "\n",
    "kernels = [ utils.DoGKernel(7,1,2),\n",
    "            utils.DoGKernel(7,2,1),]\n",
    "filter = utils.Filter(kernels, padding = 3, thresholds = 50)\n",
    "s1 = S1Transform(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"data\"\n",
    "MNIST_train = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform = s1))\n",
    "MNIST_test = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform = s1))\n",
    "MNIST_loader = DataLoader(MNIST_train, batch_size=len(MNIST_train), shuffle=False)\n",
    "MNIST_testLoader = DataLoader(MNIST_test, batch_size=len(MNIST_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kheradpisheh = SNN()\n",
    "if use_cuda:\n",
    "    kheradpisheh.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data,target = next(iter(MNIST_loader))\n",
    "# train_unsupervise(kheradpisheh, data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_unsupervise(kheradpisheh, data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the first layer\n",
      "Epoch 0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "Iteration 0\n",
      "HERE1\n",
      "(15, 2, 28, 28) (15, 32, 28, 28) (15, 32, 28, 28) (5, 3)\n",
      "YO1\n",
      "YO2\n",
      "YO3\n",
      "torch.Size([2, 4, 5]) torch.Size([5, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m data,_ \u001b[39min\u001b[39;00m MNIST_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIteration\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39miter\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     train_unsupervise(kheradpisheh, data, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39miter\u001b[39m\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     data_in \u001b[39m=\u001b[39m data_in\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m network(data_in, layer_idx)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m network\u001b[39m.\u001b[39;49mstdp(layer_idx)\n",
      "\u001b[1;32m/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstdp\u001b[39m(\u001b[39mself\u001b[39m, layer_idx):\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=148'>149</a>\u001b[0m     \u001b[39mif\u001b[39;00m layer_idx \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdp1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx[\u001b[39m\"\u001b[39;49m\u001b[39minput_spikes\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx[\u001b[39m\"\u001b[39;49m\u001b[39mpotentials\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx[\u001b[39m\"\u001b[39;49m\u001b[39moutput_spikes\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx[\u001b[39m\"\u001b[39;49m\u001b[39mwinners\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m     \u001b[39mif\u001b[39;00m layer_idx \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jeaston/PAL_Research/SpykeTorch/jack2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdp2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx[\u001b[39m\"\u001b[39m\u001b[39minput_spikes\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx[\u001b[39m\"\u001b[39m\u001b[39mpotentials\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx[\u001b[39m\"\u001b[39m\u001b[39moutput_spikes\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx[\u001b[39m\"\u001b[39m\u001b[39mwinners\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SpykeTorch-KlMlTOi6/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PAL_Research/SpykeTorch/SpykeTorch/snn.py:322\u001b[0m, in \u001b[0;36mSTDP.forward\u001b[0;34m(self, input_spikes, potentials, output_spikes, winners, kwta, inhibition_radius)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m winners \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     winners \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mget_k_winners(potentials, kwta, inhibition_radius, output_spikes)\n\u001b[0;32m--> 322\u001b[0m pairings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_pre_post_ordering(input_spikes, output_spikes, winners)\n\u001b[1;32m    323\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHERE2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m lr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/PAL_Research/SpykeTorch/SpykeTorch/snn.py:311\u001b[0m, in \u001b[0;36mSTDP.get_pre_post_ordering\u001b[0;34m(self, input_spikes, output_spikes, winners)\u001b[0m\n\u001b[1;32m    309\u001b[0m     in_tensor \u001b[39m=\u001b[39m input_latencies[:,winner[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]:winner[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m],winner[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:winner[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer\u001b[39m.\u001b[39mkernel_size[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n\u001b[1;32m    310\u001b[0m     \u001b[39mprint\u001b[39m(in_tensor\u001b[39m.\u001b[39mshape, out_tensor\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 311\u001b[0m     result\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39;49mge(in_tensor,out_tensor))\n\u001b[1;32m    312\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mYO4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Training The First Layer\n",
    "print(\"Training the first layer\")\n",
    "if os.path.isfile(\"saved_l1.net\"):\n",
    "    kheradpisheh.load_state_dict(torch.load(\"saved_l1.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,_ in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(kheradpisheh, data, 1)\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(kheradpisheh.state_dict(), \"saved_l1.net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training The Second Layer\n",
    "print(\"Training the second layer\")\n",
    "if os.path.isfile(\"saved_l2.net\"):\n",
    "    kheradpisheh.load_state_dict(torch.load(\"saved_l2.net\"))\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data,_ in MNIST_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(kheradpisheh, data, 2)\n",
    "        print(\"Done!\")\n",
    "        iter+=1\n",
    "torch.save(kheradpisheh.state_dict(), \"saved_l2.net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "# Get train data\n",
    "for data,target in MNIST_loader:\n",
    "    train_X, train_y = test(kheradpisheh, data, target, 2)\n",
    "    \n",
    "\n",
    "# Get test data\n",
    "for data,target in MNIST_testLoader:\n",
    "    test_X, test_y = test(kheradpisheh, data, target, 2)\n",
    "\n",
    "# SVM\n",
    "clf = LinearSVC(C=2.4)\n",
    "clf.fit(train_X, train_y)\n",
    "predict_train = clf.predict(train_X)\n",
    "predict_test = clf.predict(test_X)\n",
    "\n",
    "def get_performance(X, y, predictions):\n",
    "    correct = 0\n",
    "    silence = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if X[i].sum() == 0:\n",
    "            silence += 1\n",
    "        else:\n",
    "            if predictions[i] == y[i]:\n",
    "                correct += 1\n",
    "    return (correct/len(X), (len(X)-(correct+silence))/len(X), silence/len(X))\n",
    "\n",
    "print(get_performance(train_X, train_y, predict_train))\n",
    "print(get_performance(test_X, test_y, predict_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpykeTorch-KlMlTOi6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
